[
    {
        "question": "A multi-tier application runs on EC2 instances and uses RDS as the backend database. You want to monitor application and system logs in real-time and set up alerts based on certain patterns. Which AWS services can accomplish this while being cost-effective?",
        "choices": [
            "A. Amazon Kinesis Data Streams and AWS CloudTrail",
            "B. Amazon CloudWatch Logs and Amazon SNS",
            "C. AWS X-Ray and AWS CloudTrail",
            "D. Amazon Kinesis Data Firehose and Amazon SQS"
        ],
        "answer": "B. Amazon CloudWatch Logs and Amazon SNS",
        "explanation": "Amazon CloudWatch Logs can monitor application logs, while Amazon SNS can be used to send notifications based on log patterns. Choice A is incorrect because Kinesis Data Streams and CloudTrail are primarily for event data collection and auditing respectively. Choice C is incorrect because X-Ray is for analyzing application behavior and CloudTrail is for auditing. Choice D is incorrect because Kinesis Data Firehose and SQS are used for data streaming and messaging."
    },
    {
        "question": "You're operating a critical web application with an auto-scaling group of EC2 instances behind an Application Load Balancer (ALB). There's an upcoming requirement to patch the underlying EC2 instances. Which strategy ensures the highest availability?",
        "choices": [
            "A. Stop all instances, patch them, and start again",
            "B. Detach each instance one at a time, patch, and reattach",
            "C. Patch each instance one at a time without detaching from the ALB",
            "D. Use AWS Systems Manager Patch Manager to automate the patching process"
        ],
        "answer": "B. Detach each instance one at a time, patch, and reattach",
        "explanation": "Detaching each instance one at a time, patching it, and reattaching it to the load balancer will ensure that the application is always available during the patching process. Choice A is incorrect because stopping all instances would cause downtime. Choice C is incorrect because patching without detaching could lead to application errors if a health check fails. Choice D is incorrect because while AWS Systems Manager Patch Manager can automate patching, it doesn't inherently ensure high availability during the patching process."
    },
    {
        "question": "Your company uses AWS CodePipeline for continuous delivery. The application code is stored in a private GitHub repository and built using CodeBuild. However, your pipeline is failing at the Source stage. What's the most likely cause?",
        "choices": [
            "A. The AWS CodePipeline service role doesn't have the necessary permissions",
            "B. The GitHub token in AWS Secrets Manager is expired",
            "C. AWS CodePipeline doesn't support private GitHub repositories",
            "D. AWS CodeBuild cannot build the code from private GitHub repositories"
        ],
        "answer": "B. The GitHub token in AWS Secrets Manager is expired",
        "explanation": "If AWS CodePipeline cannot retrieve source code from a private GitHub repository, it's likely that the stored GitHub token has expired or is incorrect. AWS CodePipeline supports private repositories and the issue doesn't necessarily reside in CodeBuild, making Choices A, C, and D incorrect."
    },
    {
        "question": "You have a monolithic application running on an EC2 instance. Your company's strategy is to move towards a microservices architecture. How would you design the migration process to ensure minimal service disruption?",
        "choices": [
            "A. Use AWS Outposts for on-premises microservices and then migrate",
            "B. Refactor the entire application into microservices, then deploy",
            "C. Use the strangler pattern to gradually replace parts of your application",
            "D. Use AWS App Runner to containerize the entire application and manage the microservices"
        ],
        "answer": "C. Use the strangler pattern to gradually replace parts of your application",
        "explanation": "The strangler pattern allows you to incrementally replace parts of an application and is a common strategy when moving from a monolithic to a microservices architecture, which reduces service disruption. Choices A and D are incorrect as they don't ensure minimal disruption. Choice B is incorrect because refactoring the entire application at once can lead to significant service disruption."
    },
    {
        "question": "You have a static website hosted on an Amazon S3 bucket. The website includes large media files that are distributed globally. What would be the most cost-effective and performance-efficient method to serve these files?",
        "choices": [
            "A. Use Amazon EC2 instances behind an ELB",
            "B. Use Amazon S3 Transfer Acceleration",
            "C. Use Amazon CloudFront as a CDN",
            "D. Use AWS Direct Connect"
        ],
        "answer": "C. Use Amazon CloudFront as a CDN",
        "explanation": "Amazon CloudFront is a content delivery network (CDN) that caches content in edge locations around the world, providing low latency delivery. Choice A is not cost-effective for static content. Choice B incurs additional costs and is designed for transferring data into S3. Choice D provides a dedicated network connection to AWS, which is not necessary for a static website."
    },
    {
        "question": "You are designing a disaster recovery strategy for a multi-tier web application. The RTO is 3 hours, and the RPO is 15 minutes. Which AWS service can be used to meet these requirements?",
        "choices": [
            "A. AWS Snowball",
            "B. AWS Storage Gateway",
            "C. Amazon S3 One Zone-IA",
            "D. AWS Backup"
        ],
        "answer": "D. AWS Backup",
        "explanation": "AWS Backup automates backups across AWS services and on-premises applications. It meets the RTO and RPO requirements for most applications. Choices A and B are typically used for data migration, and Choice C is a storage class in Amazon S3, which doesn't provide backup capabilities by itself."
    },
    {
        "question": "You're managing an Amazon Aurora database that is being overwhelmed by large, complex queries. How can you best manage these queries while ensuring the application remains performant?",
        "choices": [
            "A. Use Aurora Replicas to offload read traffic",
            "B. Increase the size of your Aurora instance",
            "C. Implement AWS Auto Scaling",
            "D. Implement Aurora Serverless"
        ],
        "answer": "A. Use Aurora Replicas to offload read traffic",
        "explanation": "Aurora Replicas can be used to offload read traffic from the main database, helping to manage the load of large, complex queries. Choices B and C might help, but they could also increase costs without addressing the root cause. Choice D is incorrect as Aurora Serverless automatically scales based on actual consumption but it doesn't inherently manage complex queries."
    },
    {
        "question": "An application uses AWS Lambda to process records from a Kinesis data stream. You notice that records are processed more than once. What could be the reason and how could you mitigate this?",
        "choices": [
            "A. Increase the memory size for the Lambda function",
            "B. Increase the number of shards in the Kinesis data stream",
            "C. The Lambda function is throwing errors and needs error handling",
            "D. Use a FIFO (First In, First Out) queue in Amazon SQS instead of Kinesis"
        ],
        "answer": "C. The Lambda function is throwing errors and needs error handling",
        "explanation": "Lambda will retry on failures, which can result in records being processed more than once. Proper error handling in the Lambda function can mitigate this. Choices A and B may not necessarily solve the issue of multiple record processing. Choice D is incorrect because SQS FIFO queues might not be the right choice depending on the use case."
    },
    {
        "question": "You have a multi-account AWS environment managed through AWS Organizations. You need to automate the deployment of AWS Config in all existing and future accounts. What's the most efficient solution?",
        "choices": [
            "A. Use StackSets from the AWS CloudFormation service",
            "B. Create an AWS Lambda function that deploys AWS Config",
            "C. Use AWS Config Aggregator",
            "D. Manually deploy AWS Config in each account"
        ],
        "answer": "A. Use StackSets from the AWS CloudFormation service",
        "explanation": "AWS CloudFormation StackSets extends the functionality of stacks by enabling you to create, update, or delete stacks across multiple accounts and regions with a single operation. Choices B and D are manual processes which are not efficient. Choice C is incorrect because AWS Config Aggregator is used to aggregate Config data from multiple accounts, not for deployment."
    },
    {
        "question": "Your organization uses Amazon ECS to run Docker containers. As the volume of logs has increased, you need a solution to centralize the logs and analyze them. Which AWS services should you use?",
        "choices": [
            "A. AWS Glue and Amazon Athena",
            "B. Amazon CloudWatch Logs and Amazon CloudWatch Logs Insights",
            "C. Amazon Kinesis Data Firehose and Amazon QuickSight",
            "D. AWS Data Pipeline and Amazon Redshift"
        ],
        "answer": "B. Amazon CloudWatch Logs and Amazon CloudWatch Logs Insights",
        "explanation": "CloudWatch Logs centralizes logs from various AWS services, and CloudWatch Logs Insights enables you to interactively search and analyze your log data. The other options are either more complex than necessary (Choices A, C, and D) or not designed for handling logs."
    },
    {
        "question": "An application is deployed across multiple AWS regions for high availability. Each region operates independently. However, users report that occasionally they see stale data. What could be the cause and the solution?",
        "choices": [
            "A. Inconsistent read/write to Amazon S3; use S3 Transfer Acceleration",
            "B. Latency in replicating DynamoDB tables; implement DynamoDB Global Tables",
            "C. The application cache is outdated; implement Amazon ElastiCache",
            "D. Data is not correctly replicated in RDS; implement cross-region Read Replicas"
        ],
        "answer": "B. Latency in replicating DynamoDB tables; implement DynamoDB Global Tables",
        "explanation": "If an application deployed across multiple regions is occasionally serving stale data, it's possible that the DynamoDB tables are not being updated quickly enough. DynamoDB Global Tables can solve this issue by providing fully managed, multi-region, and multi-active replication. The other options may not solve the stale data issue if DynamoDB is the primary data store."
    },
    {
        "question": "You're managing an application running on Amazon EC2 instances within an Auto Scaling group. During peak usage, users report that the application becomes slow. After investigating, you find that the CPU utilization of the EC2 instances reaches 90%. How can you mitigate this issue?",
        "choices": [
            "A. Use larger EC2 instance types",
            "B. Increase the desired capacity of the Auto Scaling group",
            "C. Set up a scaling policy based on CPU utilization",
            "D. Use Amazon RDS instead of EC2"
        ],
        "answer": "C. Set up a scaling policy based on CPU utilization",
        "explanation": "Creating a scaling policy based on CPU utilization will automatically adjust the number of EC2 instances in the Auto Scaling group in response to demand. Choice A might not solve the issue if demand continues to increase. Choice B might not be necessary if the increased demand is temporary. Choice D is incorrect because RDS is a database service and is not a substitute for EC2."
    },
    {
        "question": "You're deploying an application on AWS Fargate. The application needs to access an RDS database. You decide to use AWS Secrets Manager for storing database credentials. How can your application retrieve the credentials?",
        "choices": [
            "A. Use the AWS CLI within the application to retrieve the secrets",
            "B. Mount a volume with the secret in the Fargate task",
            "C. Use an IAM role with permissions to access the secret",
            "D. Embed the AWS SDK in the application and use it to retrieve the secrets"
        ],
        "answer": "D. Embed the AWS SDK in the application and use it to retrieve the secrets",
        "explanation": "Embedding the AWS SDK within the application and using it to retrieve secrets from AWS Secrets Manager is a secure and recommended way to handle credentials. The application needs the necessary IAM permissions to access the secret. Choices A and B are not recommended methods. Choice C is partially correct as the application would still need to use the AWS SDK or CLI to retrieve the secret."
    },
    {
        "question": "A company uses AWS CodePipeline for their CI/CD workflows. They want to implement a new policy that no changes should go to the production environment on Fridays to prevent disruption over the weekend. What's the most efficient way to enforce this policy?",
        "choices": [
            "A. Use a scheduled AWS Lambda function to disable the pipeline on Fridays",
            "B. Use AWS WAF to block all traffic to the production environment on Fridays",
            "C. Use Amazon CloudWatch Events to stop the pipeline on Fridays",
            "D. Implement the policy in the AWS CodePipeline stage transition settings"
        ],
        "answer": "A. Use a scheduled AWS Lambda function to disable the pipeline on Fridays",
        "explanation": "Using a scheduled Lambda function to disable the pipeline is an efficient way to implement this policy. Choice B is incorrect because AWS WAF is a web application firewall and isn't related to CI/CD workflows. Choice C might not provide the granularity required. Choice D is incorrect as stage transition settings in CodePipeline do not include time-based controls."
    },
    {
        "question": "Your application hosted on EC2 instances is experiencing performance issues due to repeated DNS lookups. The application uses a database on AWS RDS that doesn't change IP addresses. How can you improve the performance of your application?",
        "choices": [
            "A. Use Amazon RDS Proxy",
            "B. Use Amazon Route 53 Resolver",
            "C. Enable DNS hostnames in the VPC settings",
            "D. Use Amazon ElastiCache"
        ],
        "answer": "D. Use Amazon ElastiCache",
        "explanation": "Amazon ElastiCache can be used to cache DNS query results, reducing the need for repeated DNS lookups and thereby improving application performance. Choices A and B are incorrect because they don't solve the issue of repeated DNS lookups. Choice C is incorrect as enabling DNS hostnames in the VPC settings won't necessarily improve DNS lookup performance."
    },
    {
        "question": "You have an Auto Scaling group of EC2 instances processing jobs from an SQS queue. Occasionally, some jobs take longer than the visibility timeout, causing them to be processed multiple times. How can you mitigate this issue?",
        "choices": [
            "A. Increase the visibility timeout",
            "B. Enable long polling on the SQS queue",
            "C. Use a Dead Letter Queue",
            "D. Use FIFO (First-In-First-Out) queues"
        ],
        "answer": "A. Increase the visibility timeout",
        "explanation": "Increasing the visibility timeout will prevent messages from becoming visible again before they've been fully processed. Choice B is incorrect because long polling doesn't impact message visibility after it's been received. Choice C is incorrect because a Dead Letter Queue is used for handling failed messages, not in-progress ones. Choice D is incorrect because FIFO queues won't prevent a message from being processed multiple times if it's not deleted within the visibility timeout."
    },
    {
        "question": "Your web application is hosted on EC2 instances behind an Application Load Balancer (ALB). The application stores session data in memory. Users complain about being frequently logged out. What's a possible cause and solution?",
        "choices": [
            "A. ALB is misconfigured; switch to a Network Load Balancer (NLB)",
            "B. Sticky sessions are not enabled on the ALB; enable sticky sessions",
            "C. EC2 instances are being terminated; adjust the Auto Scaling Group settings",
            "D. In-memory session data is not persisted; use Amazon ElastiCache for session management"
        ],
        "answer": "B. Sticky sessions are not enabled on the ALB; enable sticky sessions",
        "explanation": "If users are frequently being logged out, it could be because the application is storing session data in memory and the ALB is not configured to use sticky sessions. Sticky sessions bind a user's session to a specific instance, ensuring all requests from the user during the session are sent to the same instance. The other options are not likely the primary cause of users being logged out."
    },
    {
        "question": "You have a three-tier web application with web servers, app servers, and a database, all running on Amazon EC2 instances. You want to reduce costs by stopping non-production environments outside of business hours. Which AWS service can help achieve this?",
        "choices": [
            "A. AWS Auto Scaling",
            "B. AWS Instance Scheduler",
            "C. Amazon RDS automated backups",
            "D. AWS Elastic Beanstalk"
        ],
        "answer": "B. AWS Instance Scheduler",
        "explanation": "AWS Instance Scheduler can start and stop Amazon EC2 and Amazon RDS instances on a schedule, which can reduce costs for non-production environments. Choice A is incorrect because Auto Scaling is used to automatically adjust capacity to maintain performance. Choice C is not relevant as it's for database backups. Choice D is a platform for deploying and scaling applications, not for scheduling EC2 instances."
    },
    {
        "question": "You're managing a DynamoDB table with a large number of read and write requests. You notice that the application experiences throttling even when the provisioned read and write capacity units are not fully utilized. What's the most likely cause?",
        "choices": [
            "A. The application is experiencing a hot partition issue",
            "B. The DynamoDB table does not have a secondary index",
            "C. The DynamoDB table is in the wrong AWS region",
            "D. The provisioned capacity units are too high"
        ],
        "answer": "A. The application is experiencing a hot partition issue",
        "explanation": "In DynamoDB, data is distributed across multiple partitions by a partition key. If a large number of read and write requests are concentrated on a single partition (a 'hot' partition), it can lead to throttling even if the overall provisioned capacity is not fully utilized. The other options are unlikely to be the primary cause of the observed throttling."
    }
]
